{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting training set images...\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train_samples\n",
      "10000 test_samples\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation_42 (Activation)  (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " activation_43 (Activation)  (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " activation_44 (Activation)  (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 5, 5, 64)          18496     \n",
      "                                                                 \n",
      " activation_45 (Activation)  (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPooli  (None, 2, 2, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 2, 2, 64)          0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " activation_46 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_47 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 174602 (682.04 KB)\n",
      "Trainable params: 174602 (682.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "  391/50000 [..............................] - ETA: 1:35:44 - loss: 2.0603 - accuracy: 0.2315WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1000000 batches). You may need to use the repeat() function when building your dataset.\n",
      "50000/50000 [==============================] - 46s 904us/step - loss: 2.0603 - accuracy: 0.2315\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 50000\n  y sizes: 10000\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mross\\OneDrive\\Documents\\repos\\cs370\\3-2\\Ross_Michael_Assignment3.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mross/OneDrive/Documents/repos/cs370/3-2/Ross_Michael_Assignment3.ipynb#W0sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(datagen\u001b[39m.\u001b[39mflow(X_train, Y_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mross/OneDrive/Documents/repos/cs370/3-2/Ross_Michael_Assignment3.ipynb#W0sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m                                            batch_size\u001b[39m=\u001b[39mBATCH_SIZE), steps_per_epoch\u001b[39m=\u001b[39mX_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mross/OneDrive/Documents/repos/cs370/3-2/Ross_Michael_Assignment3.ipynb#W0sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m                                            epochs\u001b[39m=\u001b[39mNB_EPOCH, verbose\u001b[39m=\u001b[39mVERBOSE)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/mross/OneDrive/Documents/repos/cs370/3-2/Ross_Michael_Assignment3.ipynb#W0sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39m#model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/mross/OneDrive/Documents/repos/cs370/3-2/Ross_Michael_Assignment3.ipynb#W0sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m \u001b[39m#          epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT,\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/mross/OneDrive/Documents/repos/cs370/3-2/Ross_Michael_Assignment3.ipynb#W0sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m \u001b[39m#          verbose=VERBOSE)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/mross/OneDrive/Documents/repos/cs370/3-2/Ross_Michael_Assignment3.ipynb#W0sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mevaluate(X_test, Y_test,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/mross/OneDrive/Documents/repos/cs370/3-2/Ross_Michael_Assignment3.ipynb#W0sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m                        batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE, verbose\u001b[39m=\u001b[39;49mVERBOSE)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/mross/OneDrive/Documents/repos/cs370/3-2/Ross_Michael_Assignment3.ipynb#W0sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest score: \u001b[39m\u001b[39m\"\u001b[39m, score[\u001b[39m0\u001b[39m])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/mross/OneDrive/Documents/repos/cs370/3-2/Ross_Michael_Assignment3.ipynb#W0sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest accuracy: \u001b[39m\u001b[39m\"\u001b[39m, score[\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\mross\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\mross\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1950\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1943\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sizes: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1944\u001b[0m         label,\n\u001b[0;32m   1945\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m   1946\u001b[0m             \u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1947\u001b[0m         ),\n\u001b[0;32m   1948\u001b[0m     )\n\u001b[0;32m   1949\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1950\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 50000\n  y sizes: 10000\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "# Augmentation\n",
    "NUM_TO_AUGMENT = 5\n",
    "\n",
    "# CIFAR_10 is a set of 60k images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = tf.keras.optimizers.RMSprop()\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# augmenting\n",
    "print(\"Augmenting training set images...\")\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "xtas, ytas = [], []\n",
    "for i in range(X_train.shape[0]):\n",
    "    num_aug = 0\n",
    "    x = X_train[i] # (3, 32, 32)\n",
    "    x = x.reshape((1,) + x.shape) # (1, 3, 32)\n",
    "    for x_aug in datagen.flow(x, batch_size=1,\n",
    "                                save_to_dir='preview', save_prefix='cifar', save_format='jpeg'):\n",
    "        if num_aug >= NUM_TO_AUGMENT:\n",
    "            break\n",
    "        xtas.append(x_aug[0])\n",
    "        num_aug += 1\n",
    "\n",
    "\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train_samples')\n",
    "print(X_test.shape[0], 'test_samples')\n",
    "\n",
    "# convert to categorical\n",
    "Y_train = tf.keras.utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = tf.keras.utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_train.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "\n",
    "# network\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same',\n",
    "                                 input_shape = (IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, 3, 3))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(NB_CLASSES))\n",
    "model.add(tf.keras.layers.Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# fit the dataset\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(datagen.flow(X_train, Y_train,\n",
    "                                           batch_size=BATCH_SIZE), steps_per_epoch=X_train.shape[0],\n",
    "                                           epochs=NB_EPOCH, verbose=VERBOSE)\n",
    "#model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "#          epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT,\n",
    "#          verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "                       batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score: \", score[0])\n",
    "print(\"Test accuracy: \", score[1])\n",
    "\n",
    "# save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias in Machine Learning\n",
    "\n",
    "In categorizing these images it is important to try and root out the three main types of bias in AI.  These are Interaction Bias, Latent Bias, and Selection Bias. Interaction bias is a bias in the way people may react to a specific question.  The example given in the article was pictures of shoes.  If everyone draws shoes to look like sneakers because they are the most common, the AI will learn that shoes look like sneakers even though high-heels and sandals may also be shoes. (Xiang, 2019)\n",
    "The second type of bias is Latent Bias.  Latent Bias is when the data set used for training is incomplete. If only images from the distant past are used then the data could be skewed in a particular direction even though that is no longer true. Data from the 1800s may show a lot of early deaths due to diseases that are now cured. If a machine learning model were trained on that data, it would think that cholera is a serious problem in todays age even though this is not true.\n",
    "The third type of bias is Selection bias.  Only selecting items or representations for a particular thing to be categorized from a subsection of the total set will lead to skewing of the data.  For example if I were to train a model to determine what images are cars, but I only train it in a country with predominately small cars, it will not be accurate in a country with larger cars or trucks.\n",
    "Introducing any of these types of bias could negatively impact the functioning on an application using the model because the biased data could cause negative outcomes for the population that it was not trained on. A recent example of this was the issue with Google facial recognition incorrectly categorizing photos of Black people into incorrect categories.  This could be hurtful or dangerous for people being categorized in this way. (Small, 2023)\n",
    "\n",
    "Small, Z. (2023, July 4). Black artists say A.I. shows bias, with algorithms erasing their history. The New York Times. https://www.nytimes.com/2023/07/04/arts/design/black-artists-bias-ai.html \n",
    "Xiang, M. (2019, November 6). Bias: What it means in the Big Data World. Medium. https://towardsdatascience.com/bias-what-it-means-in-the-big-data-world-6e64893e92a1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
